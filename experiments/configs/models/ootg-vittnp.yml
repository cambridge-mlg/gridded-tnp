model:
  _target_: tnp.models.gridded_tnp.OOTGGriddedTNP
  encoder: ${swintnp_encoder}
  decoder: ${tnp_decoder}
  likelihood: ${likelihood}

swintnp_encoder:
  _target_: tnp.models.gridded_tnp.OOTGGriddedTNPEncoder
  transformer_encoder: ${transformer_encoder}
  grid_encoder: ${grid_encoder}
  xy_encoder: ${xy_encoder}
  xy_grid_encoder: ${xy_grid_encoder}
  x_encoder: ${x_encoder}

transformer_encoder:
  _target_: tnp.networks.transformer.GriddedTransformerEncoder
  grid_decoder: ${grid_decoder}
  mhsa_layer: ${mhsa_layer}
  num_layers: ${params.num_layers}

grid_decoder:
  _target_: tnp.networks.grid_decoders.MHCAGridDecoder
  mhca_layer: ${mhca_layer}
  top_k_ctot: ${params.top_k_ctot}
  roll_dims: ${params.roll_dims}

mhca_layer:
  _target_: tnp.networks.attention_layers.MultiHeadCrossAttentionLayer
  embed_dim: ${params.embed_dim}
  num_heads: ${params.num_heads}
  head_dim: ${params.head_dim}
  feedforward_dim: ${params.embed_dim}
  norm_first: ${params.norm_first}
  linear: ${params.linear_attention}

mhsa_layer:
  _target_: tnp.networks.attention_layers.MultiHeadSelfAttentionLayer
  embed_dim: ${params.embed_dim}
  num_heads: ${params.num_heads}
  head_dim: ${params.head_dim}
  feedforward_dim: ${params.embed_dim}
  norm_first: ${params.norm_first}
  linear: ${params.linear_attention}

xy_encoder:
  _target_: tnp.networks.mlp.MLP
  in_dim: ${eval:'1 + ${params.dim_y} + ${params.x_embed_dim}'}
  out_dim: ${params.embed_dim}
  num_layers: 2
  width: ${params.embed_dim}

xy_grid_encoder:
  _target_: tnp.networks.mlp.MLP
  in_dim: ${eval:'${params.dim_gridded_y} + ${params.x_embed_dim}'}
  out_dim: ${params.embed_dim}
  num_layers: 2
  width: ${params.embed_dim}

x_encoder:
  _target_: tnp.networks.mlp.MLPWithEmbedding
  embeddings:
    - ${latlon_embedding}
  in_dim: ${eval:'${latlon_embedding.num_legendre_polys}**2'}
  out_dim: ${params.x_embed_dim}
  num_layers: 0
  width: ${params.x_embed_dim}


latlon_embedding:
  _target_: tnp.networks.embeddings.SphericalHarmonicsEmbedding
  num_legendre_polys: ${params.num_legendre_polys}
  active_dims: [-2, -1]
  lonlat_dims: [-1, -2]

tnp_decoder:
  _target_: tnp.models.tnp.TNPDecoder
  z_decoder: ${z_decoder}

z_decoder:
  _target_: tnp.networks.mlp.MLP
  in_dim: ${params.embed_dim}
  out_dim: ${eval:'2 * ${params.dim_y}'}
  num_layers: 2
  width: ${params.embed_dim}

likelihood:
  _target_: tnp.likelihoods.gaussian.HeteroscedasticNormalLikelihood

optimiser:
  _target_: torch.optim.AdamW
  _partial_: True
  lr: 5.0e-4

params:
  epochs: 300
  embed_dim: 128
  num_heads: 8
  head_dim: 16
  norm_first: True
  num_layers: 5
  linear_attention: False
  top_k_ctot: 9
  x_embed_dim: 128
  num_legendre_polys: 10
  grid_encoder_grid_shape: [48, 96]
  roll_dims: [-1,]
  use_nn: True
  dist_fn:
    _target_: tnp.utils.distances.haversine_dist
    _partial_: True
    lonlat_dims: [-1, -2]


misc:
  name: OOTG-VITTNP-L${params.num_layers}-H${params.num_heads}-D${params.embed_dim}-GS${params.grid_encoder_grid_shape}-K${params.top_k_ctot}
  resume_from_checkpoint: null
  gradient_clip_val: 0.5
  plot_interval: 1
  logging: True
  pl_logger: True
